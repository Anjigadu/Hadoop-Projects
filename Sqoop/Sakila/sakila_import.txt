## Import all payments from sakila to hdfs

sqoop-import \
--connect jdbc:mysql://quickstart:3306/sakila \
--username root \
- P \
--query "SELECT  p.payment_id, p.rental_id, p.amount, p.payment_date,p.last_update, c.customer_id,  \       
                 CONCAT(c.first_name,' ',c.last_name) customer_name, \
                 s.staff_id, \
                 CONCAT(s.first_name,' ',s.last_name) staff_name, \
                 r.rental_date, r.return_date \
         FROM payment p \
         JOIN customer c \
         ON p.customer_id = c.customer_id \
         JOIN staff s \
         ON s.staff_id = p.staff_id \
         JOIN rental r \
         ON r.rental_id = p.rental_id \
         WHERE \$CONDITIONS
         " \
--target-dir /user/cloudera/output/hadoop/sqoop/sakila/payment \
--split-by payment_id \
--num-mappers 2 \


## Import all films (denormalized) from sakila db to hdfs " compressing the output "
-- Create the view as v_film at first

sqoop-import \
--connect jdbc:mysql://quickstart:3306/sakila \
--username root \
--table v_film \
--target-dir /user/cloudera/output/hadoop/sqoop/sakila/film
--compress
-m 1
--split-by film_id
-P


## Import all films from sakila db to hdfs compressing the output " using bzip2 code "

sqoop-import
--connect jdbc:mysql://quickstart:3306/sakila
--username root
--table v_film
--target-dir /user/cloudera/output/hadoop/sqoop/sakila/film_bzip
--compress
--compression-codec bzip2
-m 1
--split by film_id
-P





